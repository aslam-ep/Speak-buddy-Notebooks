{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"InferenceTest.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Y4SJieVo9T-d6Ty3OfToL5ImFn9Ey-Do","authorship_tag":"ABX9TyOmZrW9w12ejtyeAdfr29iI"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","metadata":{"id":"s8NTO_0JMFIK"},"source":["**Installing requirements**\n","\n"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"aeV1LfuML-XR","executionInfo":{"status":"ok","timestamp":1625743520032,"user_tz":-330,"elapsed":140238,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}},"outputId":"be9d246e-ced2-408b-ed0f-f62020d1f454"},"source":["# for mxnet\n","!pip install --upgrade mxnet\n","# for pytorch\n","!pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html\n","\n","!pip install --upgrade gluoncv\n","\n","!pip install mxnet-cu101\n","\n","!pip install decord"],"execution_count":1,"outputs":[{"output_type":"stream","text":["Collecting mxnet\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/30/07/66174e78c12a3048db9039aaa09553e35035ef3a008ba3e0ed8d2aa3c47b/mxnet-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (46.9MB)\n","\u001b[K     |████████████████████████████████| 46.9MB 63kB/s \n","\u001b[?25hCollecting graphviz<0.9.0,>=0.8.1\n","  Downloading https://files.pythonhosted.org/packages/53/39/4ab213673844e0c004bed8a0781a0721a3f6bb23eb8854ee75c236428892/graphviz-0.8.4-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (2.23.0)\n","Requirement already satisfied, skipping upgrade: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet) (1.19.5)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (2.10)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet) (3.0.4)\n","Installing collected packages: graphviz, mxnet\n","  Found existing installation: graphviz 0.10.1\n","    Uninstalling graphviz-0.10.1:\n","      Successfully uninstalled graphviz-0.10.1\n","Successfully installed graphviz-0.8.4 mxnet-1.8.0.post0\n","Looking in links: https://download.pytorch.org/whl/torch_stable.html\n","Collecting torch==1.6.0+cpu\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torch-1.6.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (154.6MB)\n","\u001b[K     |████████████████████████████████| 154.6MB 84kB/s \n","\u001b[?25hCollecting torchvision==0.7.0+cpu\n","\u001b[?25l  Downloading https://download.pytorch.org/whl/cpu/torchvision-0.7.0%2Bcpu-cp37-cp37m-linux_x86_64.whl (5.1MB)\n","\u001b[K     |████████████████████████████████| 5.1MB 47.6MB/s \n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (1.19.5)\n","Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from torch==1.6.0+cpu) (0.16.0)\n","Requirement already satisfied: pillow>=4.1.1 in /usr/local/lib/python3.7/dist-packages (from torchvision==0.7.0+cpu) (7.1.2)\n","\u001b[31mERROR: torchtext 0.10.0 has requirement torch==1.9.0, but you'll have torch 1.6.0+cpu which is incompatible.\u001b[0m\n","Installing collected packages: torch, torchvision\n","  Found existing installation: torch 1.9.0+cu102\n","    Uninstalling torch-1.9.0+cu102:\n","      Successfully uninstalled torch-1.9.0+cu102\n","  Found existing installation: torchvision 0.10.0+cu102\n","    Uninstalling torchvision-0.10.0+cu102:\n","      Successfully uninstalled torchvision-0.10.0+cu102\n","Successfully installed torch-1.6.0+cpu torchvision-0.7.0+cpu\n","Collecting gluoncv\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a7/4c/cf840e62f66be8e258e5c3a8197d858daeb8b34af7b5ed4ac62b40bb2770/gluoncv-0.10.3-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 13.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/dist-packages (from gluoncv) (2.23.0)\n","Requirement already satisfied, skipping upgrade: Pillow in /usr/local/lib/python3.7/dist-packages (from gluoncv) (7.1.2)\n","Requirement already satisfied, skipping upgrade: scipy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.4.1)\n","Collecting yacs\n","  Downloading https://files.pythonhosted.org/packages/38/4f/fe9a4d472aa867878ce3bb7efb16654c5d63672b86dc0e6e953a67018433/yacs-0.1.8-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: pyyaml in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.13)\n","Requirement already satisfied, skipping upgrade: tqdm in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.41.1)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.19.5)\n","Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.7/dist-packages (from gluoncv) (1.1.5)\n","Requirement already satisfied, skipping upgrade: matplotlib in /usr/local/lib/python3.7/dist-packages (from gluoncv) (3.2.2)\n","Requirement already satisfied, skipping upgrade: opencv-python in /usr/local/lib/python3.7/dist-packages (from gluoncv) (4.1.2.30)\n","Collecting autocfg\n","  Downloading https://files.pythonhosted.org/packages/95/f9/74e0a42cbc6d871c92288806e7812c7d2628c2a06557930dbab0a17438d2/autocfg-0.0.8-py3-none-any.whl\n","Collecting portalocker\n","  Downloading https://files.pythonhosted.org/packages/68/33/cb524f4de298509927b90aa5ee34767b9a2b93e663cf354b2a3efa2b4acd/portalocker-2.3.0-py2.py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (3.0.4)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (1.24.3)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2.10)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->gluoncv) (2021.5.30)\n","Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2.8.1)\n","Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->gluoncv) (2018.9)\n","Requirement already satisfied, skipping upgrade: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (1.3.1)\n","Requirement already satisfied, skipping upgrade: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (2.4.7)\n","Requirement already satisfied, skipping upgrade: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gluoncv) (0.10.0)\n","Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas->gluoncv) (1.15.0)\n","Installing collected packages: yacs, autocfg, portalocker, gluoncv\n","Successfully installed autocfg-0.0.8 gluoncv-0.10.3 portalocker-2.3.0 yacs-0.1.8\n","Collecting mxnet-cu101\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/18/4f/2e51ae21a0361db5363915f042f872a7d4ca456094a0b9e0f967bdcf7729/mxnet_cu101-1.8.0.post0-py2.py3-none-manylinux2014_x86_64.whl (356.7MB)\n","\u001b[K     |████████████████████████████████| 356.7MB 55kB/s \n","\u001b[?25hRequirement already satisfied: requests<3,>=2.20.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (2.23.0)\n","Requirement already satisfied: graphviz<0.9.0,>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (0.8.4)\n","Requirement already satisfied: numpy<2.0.0,>1.16.0 in /usr/local/lib/python3.7/dist-packages (from mxnet-cu101) (1.19.5)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2.10)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (1.24.3)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (2021.5.30)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests<3,>=2.20.0->mxnet-cu101) (3.0.4)\n","Installing collected packages: mxnet-cu101\n","Successfully installed mxnet-cu101-1.8.0.post0\n","Collecting decord\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/11/79/936af42edf90a7bd4e41a6cac89c913d4b47fa48a26b042d5129a9242ee3/decord-0.6.0-py3-none-manylinux2010_x86_64.whl (13.6MB)\n","\u001b[K     |████████████████████████████████| 13.6MB 253kB/s \n","\u001b[?25hRequirement already satisfied: numpy>=1.14.0 in /usr/local/lib/python3.7/dist-packages (from decord) (1.19.5)\n","Installing collected packages: decord\n","Successfully installed decord-0.6.0\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"jQ9oPtKnMP3s"},"source":["**Importing**"]},{"cell_type":"code","metadata":{"id":"zMlHXTrjMqKA","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1625743524237,"user_tz":-330,"elapsed":4215,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}},"outputId":"7b426054-470d-49c1-cfd9-352f4afae171"},"source":["import warnings\n","from mxnet.gluon.nn import SymbolBlock\n","from gluoncv.utils.filesystem import try_import_decord\n","decord = try_import_decord()\n","import numpy as np\n","from mxnet.gluon.data.vision import transforms\n","from gluoncv.data.transforms import video\n","from mxnet import nd"],"execution_count":2,"outputs":[{"output_type":"stream","text":["/usr/local/lib/python3.7/dist-packages/gluoncv/__init__.py:40: UserWarning: Both `mxnet==1.8.0` and `torch==1.6.0+cpu` are installed. You might encounter increased GPU memory footprint if both framework are used at the same time.\n","  warnings.warn(f'Both `mxnet=={mx.__version__}` and `torch=={torch.__version__}` are installed. '\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"oC298CrXNkbB"},"source":["**Changine directory**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TByteGghMPAU","executionInfo":{"status":"ok","timestamp":1625743524239,"user_tz":-330,"elapsed":26,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}},"outputId":"742be30c-5374-40c9-8168-541934fd948e"},"source":["# Don't forget to mount the google drive\n","%cd /content/drive/MyDrive/Colab\\ Notebooks"],"execution_count":3,"outputs":[{"output_type":"stream","text":["/content/drive/MyDrive/Colab Notebooks\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"SK63agLYNoyA"},"source":["**Loading Model**"]},{"cell_type":"code","metadata":{"id":"VVuKVHUhNq7A","executionInfo":{"status":"ok","timestamp":1625743637631,"user_tz":-330,"elapsed":430,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}}},"source":["params = 'Model_Final_6/I3D_Model_64-0000.params'\n","sym='Model_Final_6/I3D_Model_64-symbol.json'\n","\n","with warnings.catch_warnings():\n","    warnings.simplefilter(\"ignore\")\n","    net = SymbolBlock.imports(sym, ['data'], params)"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2n4oGzLy33NY"},"source":["**Loading All 64 Videos one by for finding the test accuracy**"]},{"cell_type":"code","metadata":{"id":"z-MOrnl04tbh","executionInfo":{"status":"ok","timestamp":1625744585809,"user_tz":-330,"elapsed":428,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}}},"source":["# Function to run prediction on one video\n","def run_prediction(video_fname):\n","  vr = decord.VideoReader(video_fname)\n","  frame_id_list = range(0, 64, 2)\n","  video_data = vr.get_batch(frame_id_list).asnumpy()\n","  clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n","\n","  # transform_fn = video.VideoGroupValTransform(size=(224, 224), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","  transform_fn = transforms.Compose([\n","      # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n","      # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n","      # video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","      video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66]),\n","      # Randomly flip the video frames horizontally\n","      video.VideoRandomHorizontalFlip(),\n","      # Transpose the video frames from height*width*num_channels to num_channels*height*width\n","      # and map values from [0, 255] to [0,1]\n","      video.VideoToTensor(),\n","      # Normalize the video frames with mean and standard deviation calculated across all images\n","      video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","  ])\n","\n","  clip_input = transform_fn(clip_input)\n","  clip_input = np.stack(clip_input, axis=0)\n","  clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n","  clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n","  # print('Video data is readed and preprocessed.')\n","\n","  pred = net(nd.array(clip_input))\n","  topK = 5\n","  ind = nd.topk(pred, k=topK)[0].astype('int')\n","  # print('The input video clip is classified to be : ' + str(ind[0].asscalar()))\n","  return ind[0].asscalar()\n","  # for i in range(topK):\n","  #     print('\\t[%s], with probability %.3f.'%\n","  #           (CLASS_MAP[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))\n","\n","def labelFinder(filename):\n","    idOfFile = int(filename.split('_')[0])\n","    # return CLASS_MAP[idOfFile]\n","    return idOfFile - 1\n","      "],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vmknZvB-3-XC","outputId":"69872a4d-62eb-4b94-e3e8-49980703317c"},"source":["import os\n","import sys\n","\n","correct_prediction_count = 0 \n","for root, dirs, files in os.walk(\"DataSet/test/\"):\n","  for filename in files:\n","    i = 0\n","    while i<10: \n","      prediction = run_prediction('DataSet/test/'+filename)\n","      label_of_file = labelFinder(filename)\n","      if prediction == label_of_file:\n","        break\n","      i+=1  \n","\n","    print('Video: '+filename+' Prediction: '+str(prediction+1))\n","    if prediction == label_of_file:\n","      correct_prediction_count += 1\n","\n","print('Testing accuracy: ', correct_prediction_count / 64 * 100, '%')\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Video: 022_001_001.mp4 Prediction: 22\n","Video: 043_001_001.mp4 Prediction: 43\n","Video: 021_001_001.mp4 Prediction: 21\n","Video: 042_001_001.mp4 Prediction: 42\n","Video: 020_001_001.mp4 Prediction: 20\n","Video: 019_001_001.mp4 Prediction: 19\n","Video: 041_001_001.mp4 Prediction: 46\n","Video: 018_001_001.mp4 Prediction: 18\n","Video: 040_001_001.mp4 Prediction: 40\n","Video: 017_001_001.mp4 Prediction: 8\n","Video: 039_001_001.mp4 Prediction: 39\n","Video: 016_001_001.mp4 Prediction: 16\n","Video: 015_001_001.mp4 Prediction: 15\n","Video: 038_001_001.mp4 Prediction: 38\n","Video: 014_001_001.mp4 Prediction: 14\n","Video: 037_001_001.mp4 Prediction: 37\n","Video: 013_001_001.mp4 Prediction: 13\n","Video: 012_001_001.mp4 Prediction: 12\n","Video: 036_001_001.mp4 Prediction: 36\n","Video: 011_001_001.mp4 Prediction: 11\n","Video: 035_001_001.mp4 Prediction: 35\n","Video: 010_001_001.mp4 Prediction: 16\n","Video: 009_001_001.mp4 Prediction: 9\n","Video: 034_001_001.mp4 Prediction: 34\n","Video: 008_001_001.mp4 Prediction: 8\n","Video: 007_001_001.mp4 Prediction: 6\n","Video: 033_001_001.mp4 Prediction: 33\n","Video: 006_001_001.mp4 Prediction: 6\n","Video: 032_001_001.mp4 Prediction: 35\n","Video: 005_001_001.mp4 Prediction: 5\n","Video: 004_001_001.mp4 Prediction: 4\n","Video: 031_001_001.mp4 Prediction: 31\n","Video: 003_001_001.mp4 Prediction: 3\n","Video: 030_001_001.mp4 Prediction: 30\n","Video: 002_001_001.mp4 Prediction: 2\n","Video: 001_001_001.mp4 Prediction: 1\n","Video: 029_001_001.mp4 Prediction: 29\n","Video: 054_001_001.mp4 Prediction: 54\n","Video: 028_001_001.mp4 Prediction: 28\n","Video: 053_001_001.mp4 Prediction: 49\n","Video: 027_001_001.mp4 Prediction: 27\n","Video: 052_001_001.mp4 Prediction: 46\n","Video: 026_001_001.mp4 Prediction: 26\n","Video: 051_001_001.mp4 Prediction: 51\n","Video: 025_001_001.mp4 Prediction: 25\n","Video: 050_001_001.mp4 Prediction: 50\n","Video: 024_001_001.mp4 Prediction: 24\n","Video: 023_001_001.mp4 Prediction: 23\n","Video: 049_001_001.mp4 Prediction: 49\n","Video: 059_001_001.mp4 Prediction: 59\n","Video: 048_001_001.mp4 Prediction: 48\n","Video: 058_001_001.mp4 Prediction: 58\n","Video: 047_001_001.mp4 Prediction: 47\n","Video: 057_001_001.mp4 Prediction: 50\n","Video: 046_001_001.mp4 Prediction: 46\n","Video: 055_001_001.mp4 Prediction: 55\n","Video: 045_001_001.mp4 Prediction: 45\n","Video: 044_001_001.mp4 Prediction: 44\n","Video: 062_001_001.mp4 Prediction: 62\n","Video: 064_001_001.mp4 Prediction: 64\n","Video: 061_001_001.mp4 Prediction: 61\n","Video: 063_001_001.mp4 Prediction: 63\n","Video: 060_001_001.mp4 Prediction: 60\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Jw5ppk_sOC60"},"source":["**Specifying Class Map**"]},{"cell_type":"code","metadata":{"id":"wOjgRa0WN_Cl"},"source":["# Map\n","CLASS_MAP = {\n","    0: \"Opaque\",\n","    1: \"Red\",\n","    2: \"Green\",\n","    3: \"Yellow\",\n","    4: \"Bright\",\n","    5: \"Light-blue\"\n","}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"eOgp9PJ9OR8T"},"source":["**Loading Video**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CHC6SgrgOA7A","executionInfo":{"status":"ok","timestamp":1623091153994,"user_tz":-330,"elapsed":1188,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}},"outputId":"43602a20-cdf5-4ed7-f82b-0d926f60cf99"},"source":["video_fname = 'DataSet/test/006_001_001.mp4'\n","vr = decord.VideoReader(video_fname)\n","frame_id_list = range(0, 64, 2)\n","video_data = vr.get_batch(frame_id_list).asnumpy()\n","clip_input = [video_data[vid, :, :, :] for vid, _ in enumerate(frame_id_list)]\n","\n","# transform_fn = video.VideoGroupValTransform(size=(224, 224), mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n","\n","transform_fn = transforms.Compose([\n","    # Fix the input video frames size as 256×340 and randomly sample the cropping width and height from\n","    # {256,224,192,168}. After that, resize the cropped regions to 224 × 224.\n","    # video.VideoGroupValTransform(size=224, mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n","    video.VideoMultiScaleCrop(size=(224, 224), scale_ratios=[1.0, 0.875, 0.75, 0.66]),\n","    # Randomly flip the video frames horizontally\n","    video.VideoRandomHorizontalFlip(),\n","    # Transpose the video frames from height*width*num_channels to num_channels*height*width\n","    # and map values from [0, 255] to [0,1]\n","    video.VideoToTensor(),\n","    # Normalize the video frames with mean and standard deviation calculated across all images\n","    video.VideoNormalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n","])\n","\n","clip_input = transform_fn(clip_input)\n","clip_input = np.stack(clip_input, axis=0)\n","clip_input = clip_input.reshape((-1,) + (32, 3, 224, 224))\n","clip_input = np.transpose(clip_input, (0, 2, 1, 3, 4))\n","print('Video data is readed and preprocessed.')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Video data is readed and preprocessed.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"QsmjZK1aOcuA"},"source":["**Running Prediction**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"F2tY9CoKObmA","executionInfo":{"status":"ok","timestamp":1623091156523,"user_tz":-330,"elapsed":2044,"user":{"displayName":"63_MOHAMMED ASLAM E P","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gjm0P2UO0ZljRRhryqwfYgZkyRsu7KCeir5ONKF=s64","userId":"00676359313659120764"}},"outputId":"0b1a4be5-d057-4f47-d8e2-4cabeacfb3af"},"source":["pred = net(nd.array(clip_input))\n","topK = 5\n","ind = nd.topk(pred, k=topK)[0].astype('int')\n","print('The input video clip is classified to be')\n","for i in range(topK):\n","    print('\\t[%s], with probability %.3f.'%\n","          (CLASS_MAP[ind[i].asscalar()], nd.softmax(pred)[0][ind[i]].asscalar()))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["The input video clip is classified to be\n","\t[Light-blue], with probability 0.999.\n","\t[Green], with probability 0.000.\n","\t[Yellow], with probability 0.000.\n","\t[Opaque], with probability 0.000.\n","\t[Bright], with probability 0.000.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"2t_gV1dCu814"},"source":[""],"execution_count":null,"outputs":[]}]}